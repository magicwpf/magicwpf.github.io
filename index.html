<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Pengfei Wan</title>

    <meta name="author" content="Pengfei Wan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Pengfei Wan
                </p>
                <p>
		I'm the head of the Visual Generation and Interaction Center (aka <strong>the Kling Team</strong>) at <a href="https://www.kuaishou.com/en">Kuaishou Technology</a>. I used to be the director of AI department (MT Lab) at <a href="https://www.meitu.com/en">Meitu, Inc</a>. I did my PhD at the ECE Department of <a href="https://hkust.edu.hk/">HKUST</a>, and B.E. at the EEIS Department of <a href="https://en.ustc.edu.cn/">USTC</a>.
    <br><br>
    My long-term passion is building <strong>intelligent multimodal content creation algorithms and systems, both for people (to express and live better) and for machine (to simulate and evolve better)</strong>. My recent focus is on video generation, digital human, and related topics. I am actively looking for interns and full-time employees. Drop me an email if you are interested.
                </p>
                <p style="text-align:center">
                  <a href="https://klingai.com/global">Kling</a>&nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=P6MraaYAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="mailto:wanfufeng@gmail.com">Email</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href=""><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
    
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px 20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision and graphics, generative AI, and multi-modal learning. Below is a list of selected publications in recent years.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Towards_Precise_Scaling_Laws_for_Video_Diffusion_Transformers_CVPR_2025_paper.html">
                  <span class="papertitle">FullDiT: Multi-Task Video Generative Foundation Model with Full Attention</span>
                </a>
                <br>
                Xuan Ju, Weicai Ye, Quande Liu, Qiulin Wang, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, Qiang Xu
                <br>
                <em>ICCV</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Towards_Precise_Scaling_Laws_for_Video_Diffusion_Transformers_CVPR_2025_paper.html">
                  <span class="papertitle">Towards Precise Scaling Laws for Video Diffusion Transformers</span>
                </a>
                <br>
                Yuanyang Yin, Yaqi Zhao, Mingwu Zheng, Ke Lin, Jiarong Ou, Rui Chen, Victor Shea-Jay Huang, Jiahao Wang, Xin Tao, Pengfei Wan, Di Zhang, Baoqun Yin, Wentao Zhang, Kun Gai
                <br>
                <em>CVPR</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2507.04635">
                  <span class="papertitle">MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding</span>
                </a>
                <br>
                Zhicheng Zhang, Wuyou Xia, Chenxi Zhao, Yan Zhou, Xiaoqiang Liu, Yongjie Zhu, Wenyu Qin, Pengfei Wan, Di Zhang, Jufeng Yang
                <br>
                <em>ICML Spotlight</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2412.07759">
                  <span class="papertitle">3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation</span>
                </a>
                <br>
                Xiao Fu, Xian Liu, Xintao Wang, Sida Peng, Menghan Xia, Xiaoyu Shi, Ziyang Yuan, Pengfei Wan, Di Zhang, Dahua Lin
                <br>
                <em>ICLR</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/11039616">
                  <span class="papertitle">Physically Based Facial Texture Generation in the Wild</span>
                </a>
                <br>
                Chi Wang, Junming Huang, Rong Zhang, Qi Wang, Haotian Yang, Pengfei Wan, Haibin Huang, Chongyang Ma, Weiwei Xu
                <br>
                <em>TPAMI</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10933545">
                  <span class="papertitle">DVIS++: Improved Decoupled Framework for Universal Video Segmentation</span>
                </a>
                <br>
                Tao Zhang, Xingye Tian, Yikang Zhou, Shunping Ji, Xuebo Wang, Xin Tao, Yuan Zhang, Pengfei Wan, Zhongyuan Wang, Yu Wu
                <br>
                <em>TPAMI</em>, 2025
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-72973-7_8">
                  <span class="papertitle">Agent Attention: On the Integration of Softmax and Linear Attention</span>
                </a>
                <br>
                Dongchen Han, Tianzhu Ye, Yizeng Han, Zhuofan Xia, Siyuan Pan, Pengfei Wan, Shiji Song, Gao Huang
                <br>
                <em>ECCV</em>, 2024
              </td>
            </tr>
          
          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/345208bdbbb6104616311dfc1d093fe7-Abstract-Conference.html">
                  <span class="papertitle">VideoTetris: Towards Compositional Text-to-Video Generation</span>
                </a>
                <br>
                Ye Tian, Ling Yang, Haotian Yang, Yuan Gao, Yufan Deng, Jingmin Chen, Xintao Wang, Zhaochen Yu, Xin Tao, Pengfei Wan, Di Zhang, Bin Cui
                <br>
                <em>NeurIPS</em>, 2024
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3641519.3657407">
                  <span class="papertitle">I2V-Adapter: A General Image-to-Video Adapter for Diffusion Models</span>
                </a>
                <br>
                Xun Guo, Mingwu Zheng, Liang Hou, Yuan Gao, Yufan Deng, Pengfei Wan, Di Zhang, Yufan Liu, Weiming Hu, Zhengjun Zha, Haibin Huang, Chongyang Ma
                <br>
                <em>SIGGRAPH</em>, 2024
              </td>
            </tr>

            <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/6464638c2472e4cae607f0c96a6fe774-Abstract-Conference.html">
                  <span class="papertitle">Augmentation-Aware Self-Supervision for Data-Efficient GAN Training</span>
                </a>
                <br>
                Liang Hou, Qi Cao, Yige Yuan, Songtao Zhao, Chongyang Ma, Siyuan Pan, Pengfei Wan, Zhongyuan Wang, Huawei Shen, Xueqi Cheng
                <br>
                <em>NeurIPS</em>, 2023
              </td>
            </tr>

            <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3610548.3618138">
                  <span class="papertitle">Towards Practical Capture of High-fidelity Relightable Avatars</span>
                </a>
                <br>
                Haotian Yang, Mingwu Zheng, Wanquan Feng, Haibin Huang, Yu-Kun Lai, Pengfei Wan, Zhongyuan Wang, Chongyang Ma
                <br>
                <em>SIGGRAPH Asia</em>, 2023
              </td>
            </tr>

            <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25394">
                  <span class="papertitle">FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces</span>
                </a>
                <br>
                HMengfei Xia, Yezhi Yezhi, Yuji Yuji, Yukun Lai, Qiang Li, Pengfei Wan, Zhongyuan Wang, Yong-Jin Liu
                <br>
                <em>AAAI Oral</em>, 2023
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9735342">
                  <span class="papertitle">PMP-Net++: Point Cloud Completion by Transformer-Enhanced Multi-Step Point Moving Paths</span>
                </a>
                <br>
                Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Yu-Shen Liu
                <br>
                <em>TPAMI</em>, 2022
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/d10d6b28d74c4f0fcab588feeb6fe7d6-Abstract-Conference.html">
                  <span class="papertitle">Debiased Self-Training for Semi-Supervised Learning</span>
                </a>
                <br>
                Baixu Chen, Junguang Jiang, Ximei Wang, Pengfei Wan, Jianmin Wang, Mingsheng Long
                <br>
                <em>NeurIPS Oral</em>, 2022
              </td>
            </tr>

          <tr>
              <td style="padding:10px 30px;width:80%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/9928787">
                  <span class="papertitle">Snowflake Point Deconvolution for Point Cloud Completion and Generation With Skip-Transformer</span>
                </a>
                <br>
                Peng Xiang, Xin Wen, Yu-Shen Liu, Yan-Pei Cao, Pengfei Wan, Wen Zheng, Zhizhong Han
                <br>
                <em>TPAMI</em>, 2022
              </td>
            </tr>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:50px 20px 20px 20px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        

            <tr>
              <td align="center" style="padding:0px 0px;width:5%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #ffffff;">
								 <h3>Talks</h3>
								 </div>
              </td>
              <td style="padding:0px 0px;width:80%;vertical-align:center">
                Speech on "<a href="data/tutorial_cvpr25_wpf.pdf">An Introduction to Kling and Our Research towards More Powerful Video Generation Models</a>", <br>
                CVPR Tutorial: <a href="https://world-model-tutorial.github.io/">From Video Generation to World Model</a>, Nashville TN, 2025
                <br><br>
                Roundtable forum on "The Innovations and Challenges of the Next-generation Artificial Intelligence Architecture", <br>
                <a href="https://worldaic.com.cn/">World Artificial Intelligence Conference (WAIC)</a>, Shanghai, 2024
                <br><br>
                Speech on "Kling Video Generation Models" & roundtable forum on "Multimodality, AGI, On-device AI",<br>
                <a href="https://2024.baai.ac.cn/">BAAI Conference</a>, Beijing, 2024
                <br><br>
                Speech on "Multimodal Digital Human: Technological Innovations and Industrial Applications", <br>
                China Digital Human Conference, Beijing, 2024
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:0px 0px;width:5%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #ffffff;">
								 <h3>Services</h3>
								 </div>
              </td>
              <td style="padding:0px 0px;width:80%;vertical-align:center">
                Reviewer for CVPR, ICCV, NeurIPS, ICLR, TIP, TMM, etc.
                <!-- <br><br> -->
              </td>
            </tr>

      </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td>
                <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=Qrp-1F9Vo7H0jFH9JaTZhEx82Rc19YnstXvYFbjvwXQ&cl=ffffff&w=a"></script>
              </td>
            </tr>
            <tr>
              <td style="padding:10px 0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This template is a modification of <a href="https://jonbarron.info/">Jon Barron's website</a>
                </p>
              </td>
            </tr>
          </tbody></table>


        </td>
      </tr>
    </table>


  </body>
</html>